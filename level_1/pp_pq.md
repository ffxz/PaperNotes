### INCREASING COMPACTNESS OF DEEP LEARNING BASED SPEECH ENHANCEMENT MODELS WITH PARAMETER PRUNING AND QUANTIZATION TECHNIQUES

叙述：
    语音增强很多专注于性能，但是在很多场景下需要平衡性能与实时性。
    因此，提出新的parameter pruning (PP)用来去除冗余的通道维度；另外，利用parameter quantization (PQ)，通过聚类来减少尺寸。PP和PQ相结合进行增强模型的压缩。
    实验结果表明，模型大小仅是原来的10.03 %，在性能方面STOI损伤1.43% (from 0.70 to 0.69)，PESQ损伤3.24% (from 1.85 to 1.79)。 
